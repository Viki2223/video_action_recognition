# Video Action Recognition & Tracking Pipeline
## ğŸ“Œ Overview
This project implements a **real-time video action recognition and tracking system** using **YOLOv8** for object detection, a deep learningâ€“based action recognizer for human activity classification, and a tracking module to maintain identities across frames.
It can process **single videos** or **batch datasets**, making it suitable for surveillance analytics, sports analysis, and human behavior monitoring.
---

## âœ¨ Features

* ğŸ¯ **YOLOv8-based Object Detection** â€” Fast and accurate detection of people and objects.
* ğŸƒ **Action Recognition** â€” Classifies human activities using Kinetics dataset classes.
* ğŸ” **Multi-object Tracking** â€” Tracks entities across frames for temporal consistency.
* ğŸ“‚ **Batch Video Processing** â€” Automates processing of multiple videos.
* ğŸ“Š **Progress Logging** â€” Real-time progress bars and detailed logs.
* âš™ï¸ **Configurable Settings** â€” Easily adjust model paths, thresholds, and processing parameters.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ main.py                     # Entry point for single video processing
â”œâ”€â”€ batch_video_processor.py    # Script for batch processing videos
â”œâ”€â”€ yolov8n.pt                   # Pretrained YOLOv8 weights
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ kinetics_classes.py      # Action recognition class names
â”‚   â”œâ”€â”€ settings.py              # Project configuration
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detector.py              # YOLOv8-based object detection
â”‚   â”œâ”€â”€ action_recognizer.py     # Human activity recognition
â”‚   â”œâ”€â”€ tracker.py               # Object tracking
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ video_processor.py       # Core pipeline for detection + recognition + tracking
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ video_utils.py           # Video reading/writing helpers
â”‚   â”œâ”€â”€ logger.py                # Logging utilities
â”‚   â”œâ”€â”€ fast_progress.py         # Progress bar
```

---

## ğŸ›  Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/your-repo-name.git
cd your-repo-name

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸš€ Usage

### Single Video Processing

```bash
python main.py --video_path path/to/video.mp4 --output_path results/
```

### Batch Processing

```bash
python batch_video_processor.py --input_dir videos/ --output_dir results/
```

**Command-line arguments** may include:

* `--confidence` â€” Detection confidence threshold (default: 0.25)
* `--device` â€” `cpu` or `cuda` for GPU acceleration
* `--classes` â€” List of class IDs to detect

---

## ğŸ“Š Example Output

* Bounding boxes for detected objects
* Action labels displayed over tracked persons
* Saved processed videos in the output directory

---

## ğŸ“¦ Dependencies

* Python 3.10+
* PyTorch
* Ultralytics YOLOv8
* OpenCV
* NumPy
* tqdm

*(Full list in `requirements.txt`)*

---

## ğŸ‘¤ Author

**Vikram Kumar**
[GitHub Profile](https://github.com/Viki2223) | [LinkedIn](https://www.linkedin.com/in/vikram-kumar-69a4a42a1/)

---

